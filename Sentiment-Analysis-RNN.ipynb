{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb342fd6-a03f-48fe-8486-20d958f310dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sanja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM,Dense,Activation,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2335082-e0b2-4894-b790-4e48b1b57933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "english_stops = set(stopwords.words('english'))\n",
    "def load_dataset():\n",
    "    df = pd.read_csv('D://Notebooks//Datasets//IMDB Dataset.csv//IMDB Dataset.csv')\n",
    "    x_data = df['review']       # Reviews/Input\n",
    "    y_data = df['sentiment']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa83c94-414f-4be7-9bf3-4483f7ec2b03",
   "metadata": {},
   "source": [
    "No need to down or oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d3d9a1-9554-4bca-9005-5b9b84c9b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size = 0.02, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092396fc-7edb-42ab-8bff-4ade5032c370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed14d2f5-5e26-44a5-aa0b-35086ee5a94e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in X_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))\n",
    "get_max_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83a2e74-7e1b-47ce-8b5a-9c77b1aa9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(X_train)\n",
    "x_train = token.texts_to_sequences(X_train)\n",
    "x_test = token.texts_to_sequences(X_test)\n",
    "# x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2351d6d0-c7cd-459d-bf5d-a2c4076d6682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[   16  1386     1 ...     1   285   123]\n",
      " [  116   706    21 ...     0     0     0]\n",
      " [    1    38     3 ...     0     0     0]\n",
      " ...\n",
      " [   58     6    61 ...     0     0     0]\n",
      " [22099 18075   177 ...     0     0     0]\n",
      " [  109   104    19 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[   1  335  298 ... 1903  357   10]\n",
      " [   2   41   89 ...    0    0    0]\n",
      " [ 884   97  902 ...    0    0    0]\n",
      " ...\n",
      " [   9  121  815 ...    0    0    0]\n",
      " [  23    1   90 ...    0    0    0]\n",
      " [   8  633    5 ...    0    0    0]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    }
   ],
   "source": [
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427dd3bc-ed2a-4f5f-8446-9e989391e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 32, input_length = max_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0b8227-445a-4530-8945-8432ec9b45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 130, 32)           3215808   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,240,705\n",
      "Trainable params: 3,240,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "964397e0-6743-4ce8-a26c-e267ea3446b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4757f1-b2cd-4907-802f-816a3c9ca35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "383/383 [==============================] - 41s 104ms/step - loss: 0.4265 - accuracy: 0.7753 - val_loss: 0.2777 - val_accuracy: 0.8840\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.77533, saving model to models\\LSTM.h5\n",
      "Epoch 2/5\n",
      "383/383 [==============================] - 40s 105ms/step - loss: 0.2043 - accuracy: 0.9275 - val_loss: 0.2765 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.77533 to 0.92751, saving model to models\\LSTM.h5\n",
      "Epoch 3/5\n",
      "383/383 [==============================] - 40s 104ms/step - loss: 0.1223 - accuracy: 0.9615 - val_loss: 0.3701 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.92751 to 0.96149, saving model to models\\LSTM.h5\n",
      "Epoch 4/5\n",
      "383/383 [==============================] - 40s 104ms/step - loss: 0.0799 - accuracy: 0.9771 - val_loss: 0.4834 - val_accuracy: 0.8760\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.96149 to 0.97712, saving model to models\\LSTM.h5\n",
      "Epoch 5/5\n",
      "383/383 [==============================] - 40s 105ms/step - loss: 0.0606 - accuracy: 0.9835 - val_loss: 0.4810 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.97712 to 0.98351, saving model to models\\LSTM.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d3936fbb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model.fit(x_train, Y_train, batch_size = 128, epochs = 5, callbacks=[ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1)],\n",
    "validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f738518-7a9a-41ef-ac4a-5024eb0d9c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Movie Review:  the movie has the worst direction and screenplay.....The comedy scenes are a headache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered:  ['movie worst direction screenplaythe comedy scenes headache']\n"
     ]
    }
   ],
   "source": [
    "review = str(input('Movie Review: '))\n",
    "regex = re.compile(r'[^a-zA-Z\\s]')\n",
    "review = regex.sub('', review)\n",
    "words = review.split(' ')\n",
    "filtered = [w for w in words if w not in english_stops]\n",
    "filtered = ' '.join(filtered)\n",
    "filtered = [filtered.lower()]\n",
    "\n",
    "print('Filtered: ', filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "191e51be-ce15-4fd9-a4c4-36e4096b709e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenize_words = token.texts_to_sequences(filtered)\n",
    "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b821ef8-707d-4ef8-b332-790ed8bedf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(n):\n",
    "    if n >= 0.6:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1662c33-7325-41af-8f36-1d189f5cba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00232938]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('models/LSTM.h5')\n",
    "result = loaded_model.predict(tokenize_words)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b6ca808-f7c6-4807-8cf9-0ef34185b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
